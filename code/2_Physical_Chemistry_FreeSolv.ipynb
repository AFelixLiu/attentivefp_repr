{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import seaborn as sns; sns.set_style(\"darkgrid\")\n",
    "from IPython.display import SVG, display\n",
    "import sascorer\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 8 # 69, 88\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "\n",
    "batch_size = 200\n",
    "epochs = 200\n",
    "\n",
    "p_dropout= 0.2\n",
    "fingerprint_dim = 200\n",
    "\n",
    "weight_decay = 5 # also known as l2_regularization_lambda\n",
    "learning_rate = 2.5\n",
    "output_units_num = 1 # for regression model\n",
    "radius = 2\n",
    "T = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  642\n",
      "\n",
      "number of successfully processed smiles:  642\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'hydration free energy'\n",
    "tasks = ['expt']\n",
    "\n",
    "raw_filename = \"../data/SAMPL.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.histplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n",
      "\n",
      "S\n",
      "\n",
      "C\n",
      "\n",
      "feature dicts file saved as ../data/SAMPL.pickle\n",
      "\n",
      "not processed items\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "\n",
       "<style scoped>\n",
       "\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "\n",
       "        vertical-align: middle;\n",
       "\n",
       "    }\n",
       "\n",
       "\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "\n",
       "        vertical-align: top;\n",
       "\n",
       "    }\n",
       "\n",
       "\n",
       "\n",
       "    .dataframe thead th {\n",
       "\n",
       "        text-align: right;\n",
       "\n",
       "    }\n",
       "\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "\n",
       "  <thead>\n",
       "\n",
       "    <tr style=\"text-align: right;\">\n",
       "\n",
       "      <th></th>\n",
       "\n",
       "      <th>iupac</th>\n",
       "\n",
       "      <th>smiles</th>\n",
       "\n",
       "      <th>expt</th>\n",
       "\n",
       "      <th>calc</th>\n",
       "\n",
       "      <th>cano_smiles</th>\n",
       "\n",
       "    </tr>\n",
       "\n",
       "  </thead>\n",
       "\n",
       "  <tbody>\n",
       "\n",
       "    <tr>\n",
       "\n",
       "      <th>61</th>\n",
       "\n",
       "      <td>ammonia</td>\n",
       "\n",
       "      <td>N</td>\n",
       "\n",
       "      <td>-4.29</td>\n",
       "\n",
       "      <td>-4.018</td>\n",
       "\n",
       "      <td>N</td>\n",
       "\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "\n",
       "      <th>195</th>\n",
       "\n",
       "      <td>hydrogen sulfide</td>\n",
       "\n",
       "      <td>S</td>\n",
       "\n",
       "      <td>-0.70</td>\n",
       "\n",
       "      <td>-1.135</td>\n",
       "\n",
       "      <td>S</td>\n",
       "\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "\n",
       "      <th>286</th>\n",
       "\n",
       "      <td>methane</td>\n",
       "\n",
       "      <td>C</td>\n",
       "\n",
       "      <td>2.00</td>\n",
       "\n",
       "      <td>2.446</td>\n",
       "\n",
       "      <td>C</td>\n",
       "\n",
       "    </tr>\n",
       "\n",
       "  </tbody>\n",
       "\n",
       "</table>\n",
       "\n",
       "</div>"
      ],
      "text/plain": [
       "                iupac smiles  expt   calc cano_smiles\n",
       "\n",
       "61            ammonia      N -4.29 -4.018           N\n",
       "\n",
       "195  hydrogen sulfide      S -0.70 -1.135           S\n",
       "\n",
       "286           methane      C  2.00  2.446           C"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "print(\"not processed items\")\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "test_df = remained_df.sample(frac=1/10, random_state=random_seed) # test set\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# print(len(test_df),sorted(test_df.cano_smiles.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863604\n",
      "\n",
      "atom_fc.weight torch.Size([200, 39])\n",
      "\n",
      "atom_fc.bias torch.Size([200])\n",
      "\n",
      "neighbor_fc.weight torch.Size([200, 49])\n",
      "\n",
      "neighbor_fc.bias torch.Size([200])\n",
      "\n",
      "GRUCell.0.weight_ih torch.Size([600, 200])\n",
      "\n",
      "GRUCell.0.weight_hh torch.Size([600, 200])\n",
      "\n",
      "GRUCell.0.bias_ih torch.Size([600])\n",
      "\n",
      "GRUCell.0.bias_hh torch.Size([600])\n",
      "\n",
      "GRUCell.1.weight_ih torch.Size([600, 200])\n",
      "\n",
      "GRUCell.1.weight_hh torch.Size([600, 200])\n",
      "\n",
      "GRUCell.1.bias_ih torch.Size([600])\n",
      "\n",
      "GRUCell.1.bias_hh torch.Size([600])\n",
      "\n",
      "align.0.weight torch.Size([1, 400])\n",
      "\n",
      "align.0.bias torch.Size([1])\n",
      "\n",
      "align.1.weight torch.Size([1, 400])\n",
      "\n",
      "align.1.bias torch.Size([1])\n",
      "\n",
      "attend.0.weight torch.Size([200, 200])\n",
      "\n",
      "attend.0.bias torch.Size([200])\n",
      "\n",
      "attend.1.weight torch.Size([200, 200])\n",
      "\n",
      "attend.1.bias torch.Size([200])\n",
      "\n",
      "mol_GRUCell.weight_ih torch.Size([600, 200])\n",
      "\n",
      "mol_GRUCell.weight_hh torch.Size([600, 200])\n",
      "\n",
      "mol_GRUCell.bias_ih torch.Size([600])\n",
      "\n",
      "mol_GRUCell.bias_hh torch.Size([600])\n",
      "\n",
      "mol_align.weight torch.Size([1, 400])\n",
      "\n",
      "mol_align.bias torch.Size([1])\n",
      "\n",
      "mol_attend.weight torch.Size([200, 200])\n",
      "\n",
      "mol_attend.bias torch.Size([200])\n",
      "\n",
      "output.weight torch.Size([1, 200])\n",
      "\n",
      "output.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "loss_function = nn.MSELoss()\n",
    "model = Fingerprint(radius, T, num_atom_features, num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "# optimizer = optim.SGD(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss = loss_function(mol_prediction, torch.Tensor(y_val).view(-1,1))     \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    eval_MAE_list = []\n",
    "    eval_MSE_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "    for counter, eval_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[eval_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        MAE = F.l1_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')        \n",
    "        MSE = F.mse_loss(mol_prediction, torch.Tensor(y_val).view(-1,1), reduction='none')\n",
    "#         print(x_mask[:2],atoms_prediction.shape, mol_prediction,MSE)\n",
    "        \n",
    "        eval_MAE_list.extend(MAE.data.squeeze().cpu().numpy())\n",
    "        eval_MSE_list.extend(MSE.data.squeeze().cpu().numpy())\n",
    "    return np.array(eval_MAE_list).mean(), np.array(eval_MSE_list).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.4889116 4.6295986\n",
      "\n",
      "1 3.4889457 3.3459234\n",
      "\n",
      "2 3.4868627 3.1838691\n",
      "\n",
      "3 3.4330826 3.3401072\n",
      "\n",
      "4 3.2898693 2.9853556\n",
      "\n",
      "5 3.1701777 2.8678808\n",
      "\n",
      "6 3.0564284 2.7971344\n",
      "\n",
      "7 2.8336735 2.4655533\n",
      "\n",
      "8 2.4719226 2.2088935\n",
      "\n",
      "9 2.287127 2.0497832\n",
      "\n",
      "10 2.2077966 2.018041\n",
      "\n",
      "11 2.0893774 1.9935333\n",
      "\n",
      "12 1.8485503 1.7601727\n",
      "\n",
      "13 1.6490041 1.6649685\n",
      "\n",
      "14 1.5777755 1.6284981\n",
      "\n",
      "15 1.4293296 1.4772525\n",
      "\n",
      "16 1.327753 1.3336158\n",
      "\n",
      "17 1.3639141 1.382638\n",
      "\n",
      "18 1.2715518 1.1776\n",
      "\n",
      "19 1.2102355 1.2026784\n",
      "\n",
      "20 1.1350868 1.0462834\n",
      "\n",
      "21 1.1109627 1.0017744\n",
      "\n",
      "22 1.0982748 1.0629967\n",
      "\n",
      "23 1.0786741 0.9782093\n",
      "\n",
      "24 1.096344 1.0988955\n",
      "\n",
      "25 1.0427724 1.0293592\n",
      "\n",
      "26 1.0058757 0.9393151\n",
      "\n",
      "27 1.0150261 0.9684016\n",
      "\n",
      "28 0.96819484 0.9374981\n",
      "\n",
      "29 0.9588202 0.9714065\n",
      "\n",
      "30 0.92903477 0.92668974\n",
      "\n",
      "31 0.9290548 0.9499346\n",
      "\n",
      "32 0.91146487 0.9308738\n",
      "\n",
      "33 0.9080392 0.92374986\n",
      "\n",
      "34 0.9284361 0.9211718\n",
      "\n",
      "35 0.9704258 1.0355911\n",
      "\n",
      "36 0.9314613 1.0441777\n",
      "\n",
      "37 0.8423892 0.92023414\n",
      "\n",
      "38 0.8611789 0.9110354\n",
      "\n",
      "39 0.9563538 0.9655793\n",
      "\n",
      "40 1.0293821 1.0470486\n",
      "\n",
      "41 0.8695605 0.8421852\n",
      "\n",
      "42 0.8241618 0.85899824\n",
      "\n",
      "43 0.807163 0.88604337\n",
      "\n",
      "44 0.78734684 0.8758821\n",
      "\n",
      "45 0.77236617 0.8579956\n",
      "\n",
      "46 0.761375 0.85923713\n",
      "\n",
      "47 0.74925935 0.8446477\n",
      "\n",
      "48 0.7704745 0.85803455\n",
      "\n",
      "49 0.75718606 0.8478531\n",
      "\n",
      "50 0.7618507 0.8283638\n",
      "\n",
      "51 0.7311341 0.8767507\n",
      "\n",
      "52 0.72508276 0.8174579\n",
      "\n",
      "53 0.7666273 0.8285475\n",
      "\n",
      "54 0.8072457 0.83288664\n",
      "\n",
      "55 0.74398875 0.7979583\n",
      "\n",
      "56 0.7658374 0.83128434\n",
      "\n",
      "57 0.7120842 0.7803842\n",
      "\n",
      "58 0.7058376 0.8464185\n",
      "\n",
      "59 0.7727066 0.8626394\n",
      "\n",
      "60 0.670557 0.8188596\n",
      "\n",
      "61 0.67851454 0.8160039\n",
      "\n",
      "62 0.6804413 0.83660614\n",
      "\n",
      "63 0.6425536 0.7713331\n",
      "\n",
      "64 0.6680422 0.76976025\n",
      "\n",
      "65 0.6332084 0.75911367\n",
      "\n",
      "66 0.6672612 0.81196374\n",
      "\n",
      "67 0.61793685 0.75099236\n",
      "\n",
      "68 0.61166614 0.7735851\n",
      "\n",
      "69 0.6006518 0.76635134\n",
      "\n",
      "70 0.5702351 0.7492754\n",
      "\n",
      "71 0.5856702 0.7685989\n",
      "\n",
      "72 0.549227 0.743797\n",
      "\n",
      "73 0.60967207 0.8287278\n",
      "\n",
      "74 0.55009484 0.72344553\n",
      "\n",
      "75 0.74403876 0.75586736\n",
      "\n",
      "76 0.83668405 0.97652036\n",
      "\n",
      "77 0.65979815 0.77188313\n",
      "\n",
      "78 0.5686105 0.700448\n",
      "\n",
      "79 0.5515963 0.70117146\n",
      "\n",
      "80 0.5435944 0.7224567\n",
      "\n",
      "81 0.53352475 0.725009\n",
      "\n",
      "82 0.5161656 0.7234237\n",
      "\n",
      "83 0.5108444 0.7332786\n",
      "\n",
      "84 0.4883259 0.75793654\n",
      "\n",
      "85 0.48869282 0.7402075\n",
      "\n",
      "86 0.46796247 0.73234636\n",
      "\n",
      "87 0.46145216 0.74260414\n",
      "\n",
      "88 0.46249267 0.7340735\n",
      "\n",
      "89 0.4420388 0.7214831\n",
      "\n",
      "90 0.44192 0.7258047\n",
      "\n",
      "91 0.4356227 0.7776863\n",
      "\n",
      "92 0.43360326 0.7575617\n",
      "\n",
      "93 0.41419137 0.7346601\n",
      "\n",
      "94 0.42798027 0.7177743\n",
      "\n",
      "95 0.43671784 0.7721355\n",
      "\n",
      "96 0.4159135 0.7522777\n",
      "\n",
      "97 0.40940207 0.7453004\n",
      "\n",
      "98 0.39631823 0.76806223\n",
      "\n",
      "99 0.39013296 0.7266327\n",
      "\n",
      "100 0.4054874 0.6979912\n",
      "\n",
      "101 0.39175105 0.756163\n",
      "\n",
      "102 0.38885757 0.8098543\n",
      "\n",
      "103 0.43884537 0.7610465\n",
      "\n",
      "104 0.38389546 0.7078637\n",
      "\n",
      "105 0.44026086 0.73777074\n",
      "\n",
      "106 0.4615209 0.7593217\n",
      "\n",
      "107 0.40068346 0.7525127\n",
      "\n",
      "108 0.4156446 0.6985681\n",
      "\n",
      "109 0.50117207 0.7622611\n",
      "\n",
      "110 0.36574626 0.78943306\n",
      "\n",
      "111 0.3822775 0.7711778\n",
      "\n",
      "112 0.47448546 0.76422364\n",
      "\n",
      "113 0.46211165 0.8638066\n",
      "\n",
      "114 0.46102524 0.75599647\n",
      "\n",
      "115 0.4543082 0.8107612\n",
      "\n",
      "116 0.43157881 0.7293751\n",
      "\n",
      "117 0.41874844 0.76567096\n",
      "\n",
      "118 0.39226112 0.76337135\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"train_epoch\"] = 0\n",
    "best_param[\"valid_epoch\"] = 0\n",
    "best_param[\"train_MSE\"] = 9e8\n",
    "best_param[\"valid_MSE\"] = 9e8\n",
    "\n",
    "for epoch in range(800):\n",
    "    train_MAE, train_MSE = eval(model, train_df)\n",
    "    valid_MAE, valid_MSE = eval(model, valid_df)\n",
    "#     tensorboard.add_scalars('MAE',{'train_MAE':valid_MAE, 'test_MAE':valid_MSE}, epoch)\n",
    "#     tensorboard.add_scalars('MSE',{'train_MSE':valid_MAE, 'test_MSE':valid_MSE}, epoch)\n",
    "    if train_MSE < best_param[\"train_MSE\"]:\n",
    "        best_param[\"train_epoch\"] = epoch\n",
    "        best_param[\"train_MSE\"] = train_MSE\n",
    "    if valid_MSE < best_param[\"valid_MSE\"]:\n",
    "        best_param[\"valid_epoch\"] = epoch\n",
    "        best_param[\"valid_MSE\"] = valid_MSE\n",
    "        if valid_MSE < 0.8:\n",
    "             torch.save(model.state_dict(), 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "    if (epoch - best_param[\"train_epoch\"] >8) and (epoch - best_param[\"valid_epoch\"] >18):        \n",
    "        break\n",
    "    print(epoch, np.sqrt(train_MSE), np.sqrt(valid_MSE))\n",
    "    \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch: 100 \n",
      "\n",
      " test RMSE: 0.7729235\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = Fingerprint(radius, T, num_atom_features, num_bond_features, fingerprint_dim, output_units_num, p_dropout)\n",
    "best_model_state_dict = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"valid_epoch\"])+'.pt')\n",
    "best_model.load_state_dict(best_model_state_dict)     \n",
    "best_model.cuda()\n",
    "\n",
    "best_model_dict = best_model.state_dict()\n",
    "best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "(best_model.align[0].weight == model.align[0].weight).all()\n",
    "test_MAE, test_MSE = eval(model, test_df)\n",
    "print(\"best epoch:\",best_param[\"valid_epoch\"],\"\\n\",\"test RMSE:\",np.sqrt(test_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
